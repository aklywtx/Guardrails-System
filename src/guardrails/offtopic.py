"""
Input Guardrails
off-topic detection:
filtering using sentence transformers(embedding similarity)
"""

from typing import List, Literal
from sentence_transformers import SentenceTransformer, util
import numpy as np

# Prototype queries that represent on-topic interactions, generated by AI. Some prototypes are added manually.
ON_TOPIC_PROTOTYPES = [
    # Menu inquiry
    "What dishes are on the menu?",
    "Show me the menu.",
    "What kind of food is available here?",
    "What do you have?",

    # Recommendation
    "Can you recommend something to eat?",
    "What's the most popular item?",
    "Help me choose what to order.",
    "What would you recommend?",

    # Price
    "How much is the pasta?",
    "Which dishes are under ten dollars?",
    "What's the cheapest dish?",
    "How much does that cost?",

    # Allergy
    "I'm allergic to peanuts.",
    "Which dishes are nut-free?",
    "Is this gluten-free?",
    "Does this contain dairy?",

    # Dietary preferences
    "I'm vegetarian.",
    "Show me something spicy.",
    "Give me something not too spicy.",
    "Do you have vegan options?",

    # Comparison
    "Which is better, the beef burger or the chicken burger?",
    "Compare the spicy tofu and the mild one.",

    # Order management and confirmation
    "I want the pizza.",
    "I'll take that.",
    "That sounds great.",
    "I'd like to order.",
    "Can I get the burger?",
    
    # Acknowledgement and greeting
    "Thank you for your help!",
]


class OffTopicDetector:
    """
    Off-topic detection using embedding similarity, comparing user's input against prototype on-topic queries
    to decide if the input is relevant to restaurant ordering.
    """

    def __init__(
        self,
        model_name: str="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        threshold_offtopic: float=0.35,
        threshold_clarify: float=0.4,
        prototypes: List[str]=None
    ):
        """
        Initialize the off-topic detector.

        Args:
            model_name: Name of the sentence transformer model to use(SentenceTransformer model for encoding text)
            threshold_offtopic: Similarity below this is considered off-topic
            threshold_clarify: Similarity below this is considered as need for clarification
            prototypes: List of on-topic prototype queries; ON_TOPIC_PROTOTYPES as default
        """
        self.model = SentenceTransformer(model_name)
        self.threshold_offtopic = threshold_offtopic
        self.threshold_clarify = threshold_clarify

        prototypes = prototypes or ON_TOPIC_PROTOTYPES
        self.prototype_embeddings = self.model.encode(
            prototypes,
            normalize_embeddings=True
        )

    def max_similarity(self, user_input:str) -> float:
        """
        Calculate maximum cosine similarity between user input and prototypes.

        Args:
            user_input: User's input

        Returns:
            Maximum similarity score (in 0-1)
        """
        embedding = self.model.encode([user_input], normalize_embeddings=True)
        similarities = util.cos_sim(embedding, self.prototype_embeddings).tolist()[0]
        return max(similarities)

    def detect(
        self,
        text:str,
        return_similarity:bool=False
    ) -> Literal["off_topic", "clarify", "on_topic"] | tuple:
        """
        Detect if the input text is off-topic, needs clarification, or is on-topic.

        This approach minimizes false negatives at the cost of some false positives.
        Because missing off-topic queries is worse than triggering clarification unnecessarily.

        Args:
            text: User input text
            return_similarity: If True, also return the similarity score

        Returns:
            Detection result: "off_topic", "clarify", or "on_topic"
            If return_similarity=True, returns tuple of (result, similarity_score)
        """
        similarity = self.max_similarity(text)

        if similarity < self.threshold_offtopic:
            result = "off_topic"
        elif similarity < self.threshold_clarify:
            result = "clarify"
        else:
            result = "on_topic"

        if return_similarity:
            return result, similarity
        return result


## lazy initialization
_detector_instance = None


def get_detector() -> OffTopicDetector:
    """
    Get or create the global off-topic detector instance.

    This uses a singleton pattern to avoid reloading the model multiple times.

    Returns:
        Global OffTopicDetector instance
    """
    global _detector_instance
    if _detector_instance is None:
        _detector_instance = OffTopicDetector()
    return _detector_instance


def detect_offtopic(text: str) -> Literal["off_topic", "clarify", "on_topic"]:
    """
    Convenience function for off-topic detection using the global detector.

    Args:
        text: User input text to analyze

    Returns:
        Detection result: "off_topic", "clarify", or "on_topic"
    """
    detector = get_detector()
    return detector.detect(text)
